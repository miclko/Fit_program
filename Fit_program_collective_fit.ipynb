{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define file and what sheet should be used for fit \n",
    "<span style=\"color:green\">do changes here</span>.\n",
    "\n",
    "\n",
    "The first step in the fitting process is getting the data.\n",
    "It is assumed that data is always of the type as Neil gave, in an xlsx file with different sheets.\n",
    "\n",
    "The first row has the names of the different data sets. \n",
    "and each further row has the corresponding data points for each set.\n",
    "\n",
    "In the data, 2 consecutive sheets correspond to the same experiment and thus it is sufficient to consider only every other.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Choice of parameters\n",
    "#\"../231013_DtxR_data_Michael\"\n",
    "filename = \"../230920_data_for_Michael\" #xlsx file that contains all data in the different sheets\n",
    "#extract the data to analyse from the xlsx file\n",
    "\n",
    "#choose a sheet that is being analysed in the following, structure assumed as  Neil's xlsx file\n",
    "sheetNr = 16\n",
    "#TrpR: [2,10,12]   = [#5, #13, #22]\n",
    "#CoCl:  [4,6,8,14,16] = [#8,#4,#10,#24,#7]\n",
    "\n",
    "#Not all concentrations in the file may be interesting, the following integer decides how many concentrations are \n",
    "#being ignored. With the current order in the files, this typically means low concentrations are being ignored, which\n",
    "#often are too low and have negative responses, which can't be fitted\n",
    "number_ignored_motor_concentrations = 4  #   > 0,    \n",
    "\n",
    "\n",
    "#in principle the program should be able to have multiple washing cycles different than 2\n",
    "#however, changing this number here will mean that the program expects more parameters later for the fitting.\n",
    "#without changing that later too, the program will probably break\n",
    "#so do not change the number of washes from 2, unless one knows what one has to change later.\n",
    "nrWashings = 2 #define the number of washings used\n",
    "\n",
    "### Tips for using different number of washings:  ####\n",
    "###################################################\n",
    "#if one wants to change the number washings, then one has to do straightforward changes in the pre-processing stage \n",
    "#where the cuts need more arguments. That is explained there in the comments.\n",
    "# the fitting process is more difficult to change, since it needs more variables that have to be passed (if more washings are considered), in particular the fit functions need more arguments\n",
    "#i tried to automate that, but did not find out how to make kwargs work with lmfit...\n",
    "#so one would have to rewrite the 'helper_functions.collective_spr_fit_constant_k23' and 'helper_functions.collective_spr_fit_linear_k23'\n",
    "# to have more arguments and use them. One also woud need to define these new parameters in the paramsdict for the linear and constant case\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting the data from the file\n",
    "<span style=\"color:red\">(typically no changes needed here)</span>.\n",
    "\n",
    "\n",
    "Here the data is read out of the xlsx file and stored for later usage\n",
    "\n",
    "One can also see here the names of the data showing e.g. what concentrations were used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The functions needed for getting the data from the sheets in Neil's format are stored in here\n",
    "import python_scripts.xlsx_file_read_extractor as xlsx_extractor\n",
    "#Here are some helper functions that are useful for the program\n",
    "import python_scripts.Collective_fit_functions as helper_functions\n",
    "#Here are the solutions for the rate equation problem with multiple washes\n",
    "import python_scripts.Rate_equation_solution as rateEqs\n",
    "import numpy as np\n",
    "from pandas import Series\n",
    "# from lmfit import Model, Parameter, report_fit\n",
    "import lmfit\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#The workbook that contains the full xlsx file\n",
    "used_workbook = xlsx_extractor.Get_workbook_from_xlsx_file(filename, True)\n",
    "#with the prior given sheetNr, here one gets the actual sheet from the workbook\n",
    "usedSheet = used_workbook[used_workbook.sheetnames[sheetNr]]\n",
    "\n",
    "#Get all the data entries from the sheet in a dict format. With the current format of Neil's file, the first row is ignored \n",
    "#and the second one is given as dict-kwvals which each connect to the rest of its row\n",
    "dataDict = xlsx_extractor.Get_data_from_sheet(usedSheet) \n",
    "#store all keys which correspond to the motor concentrations-data location and where the time is in the dict\n",
    "allkeys = list(dataDict.keys()) \n",
    "\n",
    "\n",
    "#output the data from the sheet for reference\n",
    "print('name of the used sheet:')\n",
    "print(usedSheet.title)\n",
    "print('found key names:')\n",
    "for x in allkeys:\n",
    "    print(x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization plot of the received data\n",
    "<span style=\"color:red\">(no changes needed here)</span>.\n",
    "\n",
    "\n",
    "Use the plot to consider what should be cut out from the data\n",
    "Especially log data is helpful, to look for negative values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timeKey = allkeys[0]\n",
    "usedDataKeys = allkeys[number_ignored_motor_concentrations:]\n",
    "# the numbers used for getting all the motor concentrations in nM\n",
    "motor_concentration=usedDataKeys \n",
    "\n",
    "\n",
    "if number_ignored_motor_concentrations != 1:\n",
    "    print('Note: not all data is being used')\n",
    "maxy = 0\n",
    "timevals = dataDict[timeKey]\n",
    "yvalslist = []\n",
    "plt.rcParams.update({'font.size': 12})\n",
    "\n",
    "for x in usedDataKeys:\n",
    "    yvals = dataDict[x]\n",
    "    if maxy < max(yvals):\n",
    "        maxy = max(yvals)\n",
    "    yvalslist.append(yvals)    \n",
    "\n",
    "fig, ax_dict = plt.subplot_mosaic([['vis']],figsize=[6,4])\n",
    "\n",
    "for (x,y) in zip(reversed(yvalslist),reversed(usedDataKeys)):\n",
    "    data = x\n",
    "    times = timevals\n",
    "    ax_dict['vis'].plot(timevals,  data , 'x-',markersize=1,lw=1,  label=y)\n",
    "\n",
    "ax_dict['vis'].set_ylabel('RU')\n",
    "ax_dict['vis'].set_xlabel(timeKey)\n",
    "\n",
    "#uncomment below to plot log scale\n",
    "# ax_dict['vis'].set_yscale('log')\n",
    " \n",
    "plt.legend(title='motor (nM)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data pre-processing step\n",
    "<span style=\"color:yellow\">(do sometimes changes here)</span>.\n",
    "\n",
    "Data thinning, finding of the peaks and cutting the peaks out is being done here. \n",
    "\n",
    "Choose good cut offs to get the best data\n",
    "\n",
    "\n",
    "Further, it is needed to cut off negative responses at the peak positions, as otherwhise fitting is not possible.\n",
    "\n",
    "One can also cut off the total length of the run, if e.g. the 2. wash is too long and nothing interesting happens anymore.\n",
    "\n",
    "Has to be changed only sometimes, depending on the response behavior, but most of the time should be ok as it is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################\n",
    "################################################\n",
    "#vary parameters\n",
    "\n",
    "#define the time in s when data should no longer be considered.\n",
    "# might be useful to cut off very long 2. washes.\n",
    "endTimeCutoff = 100\n",
    "\n",
    "#define how many data points the washing peaks should be cut off, \n",
    "#after a washing peak is registered with my program  i.e. peakposition + offset\n",
    "#The numbers correspond to individual data points, not time!, \n",
    "#so e.g. [1,1] is cutting away 1 point after each of two found peaks\n",
    "#!! it is always needed that: len(after_peak_offset) = # peaks\n",
    "after_peak_offset = [17,29]   \n",
    "\n",
    "#define how much before a registered peak should be considered\n",
    "#same idea as with start cutoff, just for individual points before the registered peak position\n",
    "#Since the first peak is used as the start of simulation, one has to define\n",
    "#! len(before_peak_offset) = len(after_peak_offset) - 1  \n",
    "before_peak_offset = [10]     \n",
    "\n",
    "#approximate number of data points\n",
    "#the program will thin out the given data to have so many points in the curve of a single motor concentration\n",
    "#the full data can't be fitted, so this reduces the data for fitting\n",
    "numberOfDataPoints = 50\n",
    "\n",
    "################################################\n",
    "################################################\n",
    "\n",
    "#define the key which corresponds to the time in the data dict\n",
    "timeKey = allkeys[0]\n",
    "# here one can supply all keys that one is interested in as data\n",
    "#here it is also evident that number_ignored_motor_concentrations needs to be >0, as it is assumed that 0 is the time\n",
    "usedDataKeys = allkeys[number_ignored_motor_concentrations:]\n",
    "\n",
    "#now the data is being processed here\n",
    "yvalsdictall = dict()\n",
    "timevalall = []\n",
    "t0_estimates = []\n",
    "yvalsdictall, timevalall, t0_estimates = helper_functions.cut_peaks_and_shrink_data(dataDict, timeKey, usedDataKeys,nrWashings, endRunTime = endTimeCutoff,offsetBeforePeak = before_peak_offset,offsetAfterPeak = after_peak_offset,nrOfDataPoints=numberOfDataPoints)\n",
    "\n",
    "# here the washing estimates is being printed\n",
    "print('found times of washings')\n",
    "print(t0_estimates)\n",
    "\n",
    "#consolidate all data into a single stacked vector which is needed for the fitting process\n",
    "data=np.array([])\n",
    "for x in usedDataKeys:\n",
    "    plt.plot(timevalall,yvalsdictall[x], label=x, marker='o',markersize=4)\n",
    "    data=np.hstack([data,yvalsdictall[x]])\n",
    "\n",
    "\n",
    "plt.legend(title='[TW] in nM')    \n",
    "plt.xlabel(timeKey)\n",
    "plt.ylabel('RU')\n",
    "plt.yscale('log')\n",
    "plt.title(f'Data of exp. {usedSheet.title}')\n",
    "#some misc. stuff if one wants to modify the plotting/ saving it\n",
    "\n",
    "# plt.savefig('Full_data_exp_' + usedSheet.title + '.pdf' )\n",
    "# plt.ylim([0,maxy])\n",
    "#choose to show everything in log scale\n",
    "# plt.yscale('log')\n",
    "# plt.xlim([0,dataDict[timeKey][-1]])\n",
    "# plt.savefig('Data_' + usedSheet.title + \".pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collective fit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear fit for $k_{23}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial state finding\n",
    "<span style=\"color:green\">(do changes here)</span>.\n",
    "\n",
    "Find here a good choice for the initial fit guess.\n",
    "\n",
    "As the problem is highly nonlinear, it is vital to start the fit with a good guess.\n",
    "\n",
    "For this stage, one can only brute force a good guess.\n",
    "\n",
    "The program will always plot your guess, so you can just vary until it looks somewhat close.\n",
    "\n",
    "### Difficulties:\n",
    "\n",
    "* It can happen, that if one chooses poor values, that the following fit creates 'NaN'-values which it says it cannot handle.\n",
    "This might be because of the strong exponential nature of all terms involved, that for long times and bad k-choices the responses will reach 0 and then the log of it becomes NaN. \n",
    "So if that happens one has to choose different start values.\n",
    "* Besides not well (or at all) converging if poor starting values were used, the lmfit will then also be quite slow (~30-40 minutes) if the choice is too far away."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define here the fit function\n",
    "linear_fit_function = lambda t,C1,C2,C3,a_k12_1,a_k12_2,k21,a_k23_1,a_k23_2,k32,t0_1,t0_2,weight_C3: helper_functions.collective_spr_fit_linear_k23(t=t,C1=C1,C2=C2,C3=C3,a_k12_1=a_k12_1,a_k12_2=a_k12_2,k21=k21,a_k23_1=a_k23_1,a_k23_2=a_k23_2,k32=k32,t0_1=t0_1,t0_2=t0_2,motor_concentrations=motor_concentration,weight_C3=weight_C3)\n",
    "#fitparameteres\n",
    "\n",
    "paramsdict = dict()\n",
    "paramsdict['C1'] = {'value':14.5, 'min': 1, 'max': 210, 'vary':True}\n",
    "paramsdict['k32'] = {'value':1.5e-5, 'min': 1e-10, 'max': 0.1, 'vary':True}\n",
    "paramsdict['k21'] = {'value':0.051, 'min': 1e-10, 'max': 1, 'vary':True}\n",
    "paramsdict['a_k12_1'] = {'value':0.0028, 'min': 1e-10, 'max': 5, 'vary':True}\n",
    "paramsdict['a_k23_1'] = {'value':4e-4, 'min': 1e-10, 'max': 5,  'vary':True}\n",
    "paramsdict['a_k12_2'] = {'value':0.0, 'vary':False}\n",
    "paramsdict['a_k23_2'] = {'value':0.0, 'vary':False}\n",
    "paramsdict['C2'] = {'value':0, 'vary':False}#finite for log fit, as otherwise response would diverge log(0)\n",
    "paramsdict['C3'] = {'value':0.00000001, 'vary':False}\n",
    "paramsdict['t0_1'] = {'value':t0_estimates[0],'min':-10,'max':1.01, 'vary':True}\n",
    "paramsdict['t0_2'] = {'value':t0_estimates[1],'min':t0_estimates[1]*0.95,'max':t0_estimates[1]*1.05, 'vary':True}\n",
    "paramsdict['weight_C3'] = {'value':2,'vary':False}\n",
    "\n",
    "# mulitplicator = 1\n",
    "# paramsdict['k21']['value'] *= mulitplicator\n",
    "# paramsdict['a_k12_1']['value'] *= mulitplicator\n",
    "# #fitting the data with linear k23 dependence\n",
    "# resultLinear = fit_spr_data_to_model(paramsdict,timevalall,np.log(data),collective_spr_fit_linear_k23, True)\n",
    "\n",
    "\n",
    "multiplicator = 4\n",
    "paramsdict['k21']['value'] *= multiplicator\n",
    "paramsdict['a_k12_1']['value'] *= multiplicator\n",
    "# plot the initial parameters to see how well the starting state is defined\n",
    "helper_functions.fit_spr_data_to_model(fitparams=paramsdict,fitdata=np.log(data),times=timevalall,fitfunction=linear_fit_function,concentrations=motor_concentration, only_show_start_fit=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear fit\n",
    "<span style=\"color:red\">(typically no changes needed)</span>.\n",
    "\n",
    "Here the data is fitted to the linear model using the above initial values and then plotted as well as saved as a pdf with an automatically generated name consisting of the type of fit and which data it belongs to.\n",
    "\n",
    "One can change the name of the pdf here partially by supplying another string to the plot_and_save_result funciton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fit linear data\n",
    "resultLinear = helper_functions.fit_spr_data_to_model(fitparams=paramsdict,fitdata=np.log(data),times=timevalall,fitfunction=linear_fit_function,concentrations=motor_concentration)\n",
    "\n",
    "#plot the result\n",
    "helper_functions.plot_and_save_result(resultLinear,data,timevalall,usedSheet.title + '_linear_fit',motor_concentration)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output the result of the fit parameters\n",
    "\n",
    "<span style=\"color:red\">(no changes needed)</span>\n",
    "\n",
    "Here the fit result is plotted and their erros given.\n",
    "\n",
    "If the fit is too poor lmfit is not able to define errors, so that is another indicator that the fit did not work out properly.\n",
    "\n",
    "One can copy the result from here, or write a script that saves this data somewhere else."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultLinear[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit of constant $k_{23}$ dependence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choice of initial parameters \n",
    "\n",
    "<span style=\"color:green\">(do changes here)</span>\n",
    "\n",
    "Here the constant fit initial values are being defined.\n",
    "\n",
    "As a simple start, the values of the linear fit are copied, as they both models should be relatively similar.\n",
    "\n",
    "Then changes are made to fit the differing behavior, like 'a_k23' being here just $k_{23}$, a constant, instead of the linear prefactor of $k_{23} = a_{k_{23}} C_\\text{motor}$ like in the linear fit.\n",
    "\n",
    "Further, the free DNA concentration 'C1' will be different, as with the lower weight of 'C3', one needs generally more DNA to be able to fit the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "#define here the fit function\n",
    "constant_fit_function = lambda t,C1,C2,C3,a_k12_1,a_k12_2,k21,a_k23_1,a_k23_2,k32,t0_1,t0_2,weight_C3: helper_functions.collective_spr_fit_constant_k23(t=t,C1=C1,C2=C2,C3=C3,a_k12_1=a_k12_1,a_k12_2=a_k12_2,k21=k21,a_k23_1=a_k23_1,a_k23_2=a_k23_2,k32=k32,t0_1=t0_1,t0_2=t0_2,motor_concentrations=motor_concentration,weight_C3=weight_C3)\n",
    "\n",
    "#the parameters for the constant fit\n",
    "paramsdictconstant = copy.deepcopy(paramsdict)\n",
    "\n",
    "paramsdictconstant['weight_C3'] = {'value':1,'vary':False}\n",
    "paramsdictconstant['a_k12_1'] = {'value':0.023, 'min': 1e-10, 'max': 5, 'vary':True}\n",
    "# paramsdictconstant['k21'] = {'value':0.78, 'min': 1e-10, 'max': 5, 'vary':True}\n",
    "\n",
    "paramsdictconstant['a_k23_1'] = {'value':0.005, 'min': 1e-10, 'max': 5,  'vary':True}\n",
    "paramsdictconstant['C1'] = {'value':12.5, 'min': 1, 'max': 210, 'vary':True}\n",
    "\n",
    "#keeping the ratio of the rates constant, but multiplying them by a factor allows for the same steady state responses\n",
    "#but change the speed with which the system thermalizes\n",
    "multiplicator = 1\n",
    "paramsdictconstant['k21']['value'] *= multiplicator\n",
    "paramsdictconstant['a_k12_1']['value'] *= multiplicator\n",
    "helper_functions.fit_spr_data_to_model(paramsdictconstant,timevalall,np.log(data),constant_fit_function,motor_concentration, True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constant fit\n",
    "<span style=\"color:red\">(no changes needed)</span>\n",
    "\n",
    "Here the constant fit is being performed using the above defined constant initial parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#fitting the data with constant k23 dependence (a_k23_1 is uased as k_23)\n",
    "resultConstant = helper_functions.fit_spr_data_to_model(paramsdictconstant,timevalall,np.log(data),constant_fit_function,motor_concentration)\n",
    "helper_functions.plot_and_save_result(resultConstant,data,timevalall,usedSheet.title + '_constant_fit',motor_concentration)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot of the fit results for the parameters of the constant fit\n",
    "\n",
    "<span style=\"color:red\">(typically no changes needed)</span>\n",
    "\n",
    "Here the fit parameter results are given with their errors for the constant case, which can be copied."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultConstant[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ideal data plotting and fitting\n",
    "\n",
    "Here one can see how to generate and fit to ideal data.\n",
    "\n",
    "Just uncomment the following two cells\n",
    "\n",
    "This might be helpful to get a better feeling on how to use the lmfit and how well it should be able to fit to the data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #define here the fit function\n",
    "\n",
    "# motor_concentration = [0.01,0.1,1,5]\n",
    "\n",
    "# #the linear dependence on k23\n",
    "# linear_data_function = lambda t,C1,C2,C3,a_k12_1,a_k12_2,k21,a_k23_1,a_k23_2,k32,t0_1,t0_2,weight_C3: helper_functions.collective_spr_fit_linear_k23(t=t,C1=C1,C2=C2,C3=C3,a_k12_1=a_k12_1,a_k12_2=a_k12_2,k21=k21,a_k23_1=a_k23_1,a_k23_2=a_k23_2,k32=k32,t0_1=t0_1,t0_2=t0_2,motor_concentrations=motor_concentration,weight_C3=2)\n",
    "# #the constant dependence on k23\n",
    "# constant_data_function = lambda t,C1,C2,C3,a_k12_1,a_k12_2,k21,a_k23_1,a_k23_2,k32,t0_1,t0_2,weight_C3: helper_functions.collective_spr_fit_constant_k23(t=t,C1=C1,C2=C2,C3=C3,a_k12_1=a_k12_1,a_k12_2=a_k12_2,k21=k21,a_k23_1=a_k23_1,a_k23_2=a_k23_2,k32=k32,t0_1=t0_1,t0_2=t0_2,motor_concentrations=motor_concentration,weight_C3=1)\n",
    "\n",
    "# #fitparameteres\n",
    "\n",
    "# times = np.linspace(0,170,40)\n",
    "# t0_estimates = [-0.1,50]\n",
    "# paramsdict = dict()\n",
    "# paramsdict['C1'] = {'value':14.5, 'min': 1, 'max': 210, 'vary':True}\n",
    "# paramsdict['k32'] = {'value':1.5e-3, 'min': 1e-10, 'max': 0.1, 'vary':True}\n",
    "# paramsdict['k21'] = {'value':0.051, 'min': 1e-10, 'max': 1, 'vary':True}\n",
    "# paramsdict['a_k12_1'] = {'value':0.0028, 'min': 1e-10, 'max': 5, 'vary':True}\n",
    "# paramsdict['a_k23_1'] = {'value':4e-4, 'min': 1e-10, 'max': 5,  'vary':True}\n",
    "# paramsdict['a_k12_2'] = {'value':0.0, 'vary':False}\n",
    "# paramsdict['a_k23_2'] = {'value':0.0, 'vary':False}\n",
    "# paramsdict['C2'] = {'value':0, 'vary':False}#finite for log fit, as otherwise response would diverge log(0)\n",
    "# paramsdict['C3'] = {'value':0.00000001, 'vary':False}\n",
    "# paramsdict['t0_1'] = {'value':t0_estimates[0],'min':-10,'max':1.01, 'vary':True}\n",
    "# paramsdict['t0_2'] = {'value':t0_estimates[1],'min':t0_estimates[1]*0.95,'max':t0_estimates[1]*1.05, 'vary':True}\n",
    "# paramsdict['weight_C3'] = {'value':2,'vary':False}\n",
    "# import lmfit\n",
    "# parametersdict = dict()\n",
    "# for x in paramsdict:\n",
    "#     parametersdict[x] = paramsdict[x]['value']\n",
    "# idealdata = np.exp(linear_data_function(times, **parametersdict))\n",
    "\n",
    "# import matplotlib.pyplot as plt\n",
    "# for (y,z) in zip(np.reshape(idealdata,(len(motor_concentration),len(times))),motor_concentration):\n",
    "#         plt.plot(times,y, '--', label=z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #fit linear data\n",
    "# #choose some different values for the initial point of the fit process\n",
    "# #depending how far away, it will be able to fit perfectly\n",
    "# paramsdict['C1']['value'] = 20\n",
    "# paramsdict['a_k12_1']['value'] = 0.001\n",
    "\n",
    "# #show initial parameter choice\n",
    "# parametersdict = dict()\n",
    "# for x in paramsdict:\n",
    "#     parametersdict[x] = paramsdict[x]['value']\n",
    "# initialGuess = linear_data_function(times, **parametersdict)\n",
    "\n",
    "# import matplotlib.pyplot as plt\n",
    "# for (y,z,k) in zip(np.reshape(idealdata,(len(motor_concentration),len(times))),motor_concentration, np.reshape(initialGuess,(len(motor_concentration),len(times)))):\n",
    "#         plt.plot(times,np.log(y), '--', label=z)\n",
    "#         plt.plot(times,k, '*')\n",
    "# plt.legend()\n",
    "# plt.xlabel('time in s')\n",
    "# plt.title('initial guess')\n",
    "# plt.ylabel('log(response)')\n",
    "# plt.show()\n",
    "# fitideal = helper_functions.fit_spr_data_to_model(fitparams=paramsdict,fitdata=np.log(idealdata),times=times,fitfunction=linear_data_function,concentrations=motor_concentration)\n",
    "\n",
    "# #plot the result\n",
    "# helper_functions.plot_and_save_result(fitideal,idealdata,times,usedSheet.title + '_ideal_fit',motor_concentration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
