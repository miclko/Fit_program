{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Choice of parameters\n",
    "\n",
    "filename = \"../230911_data_for_Michael\" #xlsx file that contains all data in the different sheets\n",
    "#extract the data to analyse from the xlsx file\n",
    "sheetNr = 8\n",
    "#TrpR: [2,10,12]\n",
    "#CoCl:  [4,6,8,14,16]\n",
    "setsUsedForFitting = 3  #   > 0, <  number of concentrations, typically have to kick out some data due to poor behavior (negative concentrations etc),\n",
    "                        # in particular the low concentration cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################\n",
    "######################################\n",
    "## Choice of sheet\n",
    "######################################\n",
    "######################################\n",
    "\n",
    "from python_scripts.xlsx_file_read_extractor import *\n",
    "from python_scripts.helper_functions import *\n",
    "from python_scripts.Fit_functions import *\n",
    "from python_scripts.Rate_equation_solution import *\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "used_workbook = Get_workbook_from_xlsx_file(filename, True)\n",
    "usedSheet = used_workbook[used_workbook.sheetnames[sheetNr]]   #sheet decides the experiment, use 2+ for experiments, 2/3, 4/5 etc are the same, just different channels\n",
    "dataDict = Get_data_from_sheet(usedSheet) #contains all data in form of dictionary, splitting it up by the used concentrations (and also time extra)\n",
    "allkeys = list(dataDict.keys()) #keys for the data dict\n",
    "print('name of the used sheet:')\n",
    "print(usedSheet.title)\n",
    "print('found key names:')\n",
    "for x in allkeys:\n",
    "    print(x)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot the data to see what it looks like and what has to be done later\n",
    "#just for visualization, nothing has to be done here\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "timeKey = allkeys[0]\n",
    "usedDataKeys = allkeys[setsUsedForFitting:]\n",
    "if setsUsedForFitting != 1:\n",
    "    print('Note: not all data is being used')\n",
    "maxy = 0\n",
    "timevals = dataDict[timeKey]\n",
    "yvalslist = []\n",
    "\n",
    "\n",
    "\n",
    "for x in usedDataKeys:\n",
    "    yvals = dataDict[x]\n",
    "    if maxy < max(yvals):\n",
    "        maxy = max(yvals)\n",
    "    yvalslist.append(yvals)    \n",
    "    # plt.plot(timevals,yvals, label=x)\n",
    "\n",
    "# plt.figure(figsize=[5,3])\n",
    "fig, ax_dict = plt.subplot_mosaic([['vis','log']],figsize=[9,4])#,\n",
    "                                #   empty_sentinel=\"BLANK\")\n",
    "\n",
    "\n",
    "for (x,y) in zip(yvalslist,usedDataKeys):\n",
    "    ax_dict['vis'].plot(timevals, x, 'x-',markersize=1,lw=1,  label=y)\n",
    "    ax_dict['log'].plot(timevals, x, 'x-',markersize=1,lw=1,  label=y)\n",
    "\n",
    "# ax_dict[x].set_title(x + ' fit params')\n",
    "ax_dict['vis'].set_ylabel('RU')\n",
    "ax_dict['vis'].set_xlabel(timeKey)\n",
    "ax_dict['vis'].legend()\n",
    "ax_dict['log'].set_xlabel(timeKey)\n",
    "ax_dict['log'].set_yscale('log')\n",
    "ax_dict['log'].set_title('logscale')\n",
    "ax_dict['vis'].set_xlim([-1,dataDict[timeKey][-1]])\n",
    "ax_dict['log'].set_xlim([-1,dataDict[timeKey][-1]])\n",
    "    \n",
    "plt.tight_layout()    \n",
    "plt.suptitle(f'Data of exp. {usedSheet.title}')\n",
    "\n",
    "\n",
    "# plt.ylim([-2,30])\n",
    "# plt.savefig('Full_data_exp_' + usedSheet.title + '.pdf' )\n",
    "# plt.ylim([0,maxy])\n",
    "# plt.ylim([1e0,1e2])\n",
    "plt.xlim([-1,dataDict[timeKey][-1]])\n",
    "# plt.savefig('Data_' + usedSheet.title + \".pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot the data to see what it looks like and what has to be done later\n",
    "\n",
    "#Choose what is  used in analysis\n",
    "#Note that fitting is done with the logarithm of the data, so one has to make sure, that  the used data sets are valid (low concentrations have ~0 RU, which can't be fitted)\n",
    "#to see the problem, one  can plot in yscale (uncomment below statement) and observe the bad behavior of them\n",
    "timeKey = allkeys[0]\n",
    "usedDataKeys = allkeys[setsUsedForFitting:]\n",
    "\n",
    "\n",
    "#######################################################################\n",
    "#######################################################################\n",
    "#######################################################################\n",
    "#important choice of the cutout of the washing peaks, choose such that the behavior is regular\n",
    "#might be possible to partially automize this, as the washing peaks are very strong, could maybe write a function that tries to do this automatically\n",
    "startcuts = [2420,3630]  #start cut value of each washing (# elements should be the number of washings)\n",
    "endcuts = [3570, -1000] #end cut value of each washing, \n",
    "#i.e. data[startcuts[0]:endcuts[0]] is the interval that is being used for the 1. washing and so on for the next washings\n",
    "nrOfDataPoints = 300 #choose how many data points should be used (rate data has too many points, \n",
    "#we can strip some data without loss of accuracy, but also increase of fit speed)\n",
    "#######################################################################\n",
    "#######################################################################\n",
    "#######################################################################\n",
    "\n",
    "yvalsdict = dict() #contains all cutted data sets\n",
    "t0_estimates = [dataDict[timeKey][x] for x in startcuts] #get the times of the cuts as t0 estimates\n",
    "timevals = Single_list_cut(dataDict[timeKey], startcuts,endcuts)\n",
    "list_shrinker(timevals,nrOfDataPoints)\n",
    "maxy = 0\n",
    "\n",
    "timevals\n",
    "for x in usedDataKeys:\n",
    "    yvals = Single_list_cut(dataDict[x], startcuts,endcuts)\n",
    "    list_shrinker(yvals,nrOfDataPoints)\n",
    "    yvalsdict[x] = yvals\n",
    "    if maxy < max(yvals):\n",
    "        maxy = max(yvals)\n",
    "    plt.plot(timevals,yvals, label=x, marker='o',markersize=4)\n",
    "plt.legend()    \n",
    "plt.xlabel(timeKey)\n",
    "plt.ylabel('RU')\n",
    "plt.title(f'Data of exp. {usedSheet.title}')\n",
    "# plt.ylim([-2,30])\n",
    "# plt.savefig('Full_data_exp_' + usedSheet.title + '.pdf' )\n",
    "# plt.ylim([0,maxy])\n",
    "#choose to show everything in log scale\n",
    "# plt.yscale('log')\n",
    "# plt.ylim([1e0,1e2])\n",
    "# plt.xlim([0,dataDict[timeKey][-1]])\n",
    "# plt.savefig('Data_' + usedSheet.title + \".pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################\n",
    "################################################\n",
    "#if fitting does not work, might have to adjust fit params here\n",
    "#visualization might also later change, if other fit params are used\n",
    "#Last difficult thing to do is the generation of arbitrary figures\n",
    "#might have to try to generalize this via a function for all data of interest\n",
    "################################################\n",
    "################################################\n",
    "\n",
    "startValDict = dict()\n",
    "startValDict['k12'] = [[0.3,0],[True,False]]\n",
    "startValDict['k21'] = [[0.03,0.4],[True,True]]\n",
    "startValDict['k23'] = [[0.01,0.01],[True,True]]\n",
    "startValDict['k32'] = [[0.001,0.001],[True,True]]\n",
    "startValDict['C1_start'] = [70,True]\n",
    "startValDict['C2_start'] = [0.0001,False]\n",
    "startValDict['C3_start'] = [0.0001,False]\n",
    "startValDict['t_0'] = [t0_estimates,[True,True]]\n",
    "nrWashings = len(startValDict['k12'][0])\n",
    "\n",
    "boundValDict = dict()\n",
    "boundValDict['k12'] = [0,1]  #lower and upper values [[lower bounds], [upper bounds]], will partially ignore if false chosen for individual parts\n",
    "boundValDict['k21'] = [0,1]   #same lower/upper bounds for all params\n",
    "boundValDict['k23'] = [0,0.2]\n",
    "boundValDict['k32'] = [0,0.1]\n",
    "boundValDict['C1_start'] = [2,100] #if no fit, then no keyword stored of it, see C2,C3\n",
    "boundValDict['t_0'] = [[x - 2 for x in startValDict['t_0'][0]],[x + 2 for x in startValDict['t_0'][0]]]\n",
    "\n",
    "\n",
    "# Fit_to_function_multiple_washes(timelist,datalist,startValDict,boundValDict,nrWashings)\n",
    "\n",
    "allResults = dict()\n",
    "for x in yvalsdict.keys():\n",
    "    print('fitting for ' + str(x))\n",
    "    resultfit = Fit_to_function_multiple_washes(timevals,yvalsdict[x],startValDict, boundValDict,nrWashings)\n",
    "    allResults[x] = resultfit\n",
    "    plt.plot(timevals,yvalsdict[x], label=x)\n",
    "    # print(resultfit[0])\n",
    "    plotOfFit = resultfit[2].call_full_function(timevals,*resultfit[0])\n",
    "    # print(resultfit[2].fit_positions_and_names())\n",
    "    plt.plot(timevals,np.array(plotOfFit[1]) + np.array(plotOfFit[2]), '--')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#here the rest of plotting all the fitting parameters, for understanding what happened\n",
    "#also the interesting vals, then finished with my part for fitting all\n",
    "#probably best to create another class/function that extracts whatever i want from the dict of interest\n",
    "interestingstuff = [[],[],[]]\n",
    "xvals = []\n",
    "for x in allResults.keys():\n",
    "    xvals.append(x)\n",
    "    # print(resultfit[2].fit_positions_and_names())\n",
    "    t0_fitted = [allResults[x][0][-1]]\n",
    "    t0Concentrations = allResults[x][2].call_full_function(t0_fitted,*allResults[x][0])\n",
    "    interestingstuff[0].append(t0Concentrations[0][0])\n",
    "    interestingstuff[1].append(t0Concentrations[1][0])\n",
    "    interestingstuff[2].append(t0Concentrations[2][0])\n",
    "\n",
    "plt.plot(xvals, interestingstuff[0], 'X--')\n",
    "plt.plot(xvals, interestingstuff[1], 'X--')\n",
    "plt.plot(xvals, interestingstuff[2], 'X--')\n",
    "plt.xlabel('Motor concentration in nM')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
